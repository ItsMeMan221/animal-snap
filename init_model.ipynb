{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3 hewan"
      ],
      "metadata": {
        "id": "xzLAc3u2wO0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "#zip_path = '/content/arcfox-cheet-chimp.zip'\n",
        "zip_path = '/content/chimp-cheet-fox.zip'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')  # Extract the contents to the 'dataset' folder\n",
        "\n",
        "# Load the dataset\n",
        "data_dir = 'dataset'\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=123,\n",
        "    image_size=(32, 32),\n",
        "    batch_size=32\n",
        ")\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=123,\n",
        "    image_size=(32, 32),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Preprocess the data\n",
        "train_ds = train_ds.map(lambda x, y: (x / 255.0, y))\n",
        "test_ds = test_ds.map(lambda x, y: (x / 255.0, y))\n",
        "\n",
        "# Define the CNN architecture\n",
        "model2 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model2.fit(train_ds, validation_data=test_ds, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model2.evaluate(test_ds, verbose=2)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a524385-8d1f-4cad-e158-94bd8b2355c0",
        "id": "E7-k7qv3wNT0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1421 files belonging to 3 classes.\n",
            "Using 1137 files for training.\n",
            "Found 1421 files belonging to 3 classes.\n",
            "Using 284 files for validation.\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 8s 169ms/step - loss: 1.1625 - accuracy: 0.4635 - val_loss: 0.7940 - val_accuracy: 0.6549\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 5s 124ms/step - loss: 0.6721 - accuracy: 0.7282 - val_loss: 0.7502 - val_accuracy: 0.6585\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 5s 123ms/step - loss: 0.5238 - accuracy: 0.8004 - val_loss: 0.4188 - val_accuracy: 0.8556\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 6s 144ms/step - loss: 0.4414 - accuracy: 0.8399 - val_loss: 0.4110 - val_accuracy: 0.8310\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 6s 151ms/step - loss: 0.4315 - accuracy: 0.8355 - val_loss: 0.4429 - val_accuracy: 0.8380\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 5s 122ms/step - loss: 0.4414 - accuracy: 0.8408 - val_loss: 0.3664 - val_accuracy: 0.8768\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 7s 161ms/step - loss: 0.3640 - accuracy: 0.8698 - val_loss: 0.3513 - val_accuracy: 0.8838\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 5s 123ms/step - loss: 0.3834 - accuracy: 0.8610 - val_loss: 0.3309 - val_accuracy: 0.8908\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 6s 164ms/step - loss: 0.3444 - accuracy: 0.8716 - val_loss: 0.3646 - val_accuracy: 0.8732\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 5s 121ms/step - loss: 0.3699 - accuracy: 0.8672 - val_loss: 0.3113 - val_accuracy: 0.9014\n",
            "9/9 - 2s - loss: 0.3113 - accuracy: 0.9014 - 2s/epoch - 171ms/step\n",
            "Test accuracy: 0.9014084339141846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "uploaded_image_path = '/content/2-cheetah-on-the-brown-grass-lawn-67553-1280x853.jpg'  # Replace with the path to your uploaded image\n",
        "\n",
        "# Load and preprocess the uploaded image\n",
        "uploaded_image = image.load_img(uploaded_image_path, target_size=(32, 32))\n",
        "uploaded_image = image.img_to_array(uploaded_image)\n",
        "uploaded_image = uploaded_image / 255.0\n",
        "uploaded_image = np.expand_dims(uploaded_image, axis=0)\n",
        "predictions = model2.predict(uploaded_image)\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "class_labels = [\"Arctic Fox\",\"Chimpanzee\",\"Cheetah\"]\n",
        "predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "print(\"Predicted Class:\", predicted_class_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHs-3oX231by",
        "outputId": "c31338f3-f041-4e5a-86aa-e0000d74085b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "Predicted Class: Cheetah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save('model2.h5')"
      ],
      "metadata": {
        "id": "9Gxo-EiHwqOm"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}